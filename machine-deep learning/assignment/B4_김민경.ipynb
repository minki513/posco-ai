{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:30.035967Z",
     "iopub.status.busy": "2021-09-29T08:08:30.035335Z",
     "iopub.status.idle": "2021-09-29T08:08:30.131284Z",
     "shell.execute_reply": "2021-09-29T08:08:30.130451Z",
     "shell.execute_reply.started": "2021-09-29T08:08:30.035872Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:30.133301Z",
     "iopub.status.busy": "2021-09-29T08:08:30.133025Z",
     "iopub.status.idle": "2021-09-29T08:08:30.137126Z",
     "shell.execute_reply": "2021-09-29T08:08:30.136232Z",
     "shell.execute_reply.started": "2021-09-29T08:08:30.133267Z"
    }
   },
   "outputs": [],
   "source": [
    "# You must modify this root to your data path!\n",
    "root = '/kaggle/input/aibd-15/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:30.138848Z",
     "iopub.status.busy": "2021-09-29T08:08:30.138562Z",
     "iopub.status.idle": "2021-09-29T08:08:34.558448Z",
     "shell.execute_reply": "2021-09-29T08:08:34.557725Z",
     "shell.execute_reply.started": "2021-09-29T08:08:30.138798Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================== Do not edit this shell =====================\n",
    "\n",
    "# Dataset Definition\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, root, train, transform=None):\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            root = root + 'train.csv'\n",
    "        else:\n",
    "            root = root + 'test.csv'\n",
    "        self.csv = pd.read_csv(root, header=None)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            label = torch.tensor(self.csv.iloc[index,0], dtype=torch.long)\n",
    "            img = np.array(self.csv.iloc[index,1:]/255).reshape(28, 28)\n",
    "            img = Image.fromarray(img)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        else:\n",
    "            img = np.array(self.csv.loc[index]/255).reshape(28, 28)\n",
    "            img = Image.fromarray(img)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img\n",
    "        \n",
    "# ============================== Do not edit this shell ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:38.024719Z",
     "iopub.status.busy": "2021-09-29T08:08:38.024011Z",
     "iopub.status.idle": "2021-09-29T08:08:38.850712Z",
     "shell.execute_reply": "2021-09-29T08:08:38.850011Z",
     "shell.execute_reply.started": "2021-09-29T08:08:38.024681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Library Importation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:38.852589Z",
     "iopub.status.busy": "2021-09-29T08:08:38.852266Z",
     "iopub.status.idle": "2021-09-29T08:08:38.906101Z",
     "shell.execute_reply": "2021-09-29T08:08:38.905127Z",
     "shell.execute_reply.started": "2021-09-29T08:08:38.852554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device Preparation\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{\"CPU\" if device == \"cpu\" else \"GPU\"} will be used in training/validation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:39.978451Z",
     "iopub.status.busy": "2021-09-29T08:08:39.977616Z",
     "iopub.status.idle": "2021-09-29T08:08:39.983692Z",
     "shell.execute_reply": "2021-09-29T08:08:39.982668Z",
     "shell.execute_reply.started": "2021-09-29T08:08:39.978401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper Parameter\n",
    "## Data Loader\n",
    "batch_size = 32\n",
    "\n",
    "## Model\n",
    "hidden_layer = 200\n",
    "\n",
    "## Learning\n",
    "logging_dispfig = True\n",
    "maximum_epoch = 35\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:41.752243Z",
     "iopub.status.busy": "2021-09-29T08:08:41.751966Z",
     "iopub.status.idle": "2021-09-29T08:08:43.705922Z",
     "shell.execute_reply": "2021-09-29T08:08:43.705049Z",
     "shell.execute_reply.started": "2021-09-29T08:08:41.752215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "train_data = CharDataset(root, train=True, transform=ToTensor())\n",
    "train_data, valid_data = random_split(train_data,\n",
    "                                      [round(len(train_data)*0.9),\n",
    "                                       round(len(train_data)*0.1)])\n",
    "test_data = CharDataset(root, train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:44.632683Z",
     "iopub.status.busy": "2021-09-29T08:08:44.631927Z",
     "iopub.status.idle": "2021-09-29T08:08:50.173427Z",
     "shell.execute_reply": "2021-09-29T08:08:50.171849Z",
     "shell.execute_reply.started": "2021-09-29T08:08:44.632632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the data\n",
    "print('===================== Check the data =========================\\n')\n",
    "print(f'Train dataset length = {len(train_data)}')\n",
    "print(f'Valid dataset length = {len(valid_data)}')\n",
    "print(f'Test dataset length = {len(test_data)}\\n')\n",
    "\n",
    "train_0_x, train_0_y = train_data[0]\n",
    "print(f'Content of Y (Label, type={type(train_0_y)}) = {train_0_y}')\n",
    "print(f'Shape of X (Data, type={type(train_0_x)}) = {train_0_x.shape}')\n",
    "plt.figure(1)\n",
    "plt.imshow(train_0_x.squeeze())\n",
    "plt.title(f'train_0_x ({train_0_x.squeeze().shape})')\n",
    "plt.show()\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
    "                          pin_memory=True,drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=len(valid_data), pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), pin_memory=True)\n",
    "\n",
    "# Examine the data loader\n",
    "print('================== Check the data loader ======================\\n')\n",
    "train_enumerator = enumerate(train_loader)\n",
    "ex_batch_idx, (ex_data, ex_label) = next(train_enumerator)\n",
    "print(f'Idx: {ex_batch_idx} / X.shape = {ex_data.shape} / Y.shape = {ex_label.shape}\\n')\n",
    "print(f'Y[0:{batch_size}] = {ex_label}')\n",
    "preview_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:50.175561Z",
     "iopub.status.busy": "2021-09-29T08:08:50.175122Z",
     "iopub.status.idle": "2021-09-29T08:08:50.196907Z",
     "shell.execute_reply": "2021-09-29T08:08:50.196187Z",
     "shell.execute_reply.started": "2021-09-29T08:08:50.175523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    net = nn.Sequential(\n",
    "        nn.Linear(len(train_0_x.view([-1])), hidden_layer),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_layer, 10, bias=False)\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Epoch\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "    \n",
    "def epoch(data_loader):\n",
    "    # One epoch : gets data_loader as input and returns loss / accuracy, and\n",
    "    #             last prediction value / its label(truth) value for future use\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc = [], []\n",
    "\n",
    "    last_out, last_label = None, None\n",
    "    last_grad_performed = False\n",
    "\n",
    "    # Mini-batch iterations\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.view([len(_data), -1]).to(device), _label.to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        onehot_out = net(data)\n",
    "\n",
    "        # 2. Calculate accuracy\n",
    "        _, out = torch.max(onehot_out, 1)\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label)\n",
    "        iter_acc.append(acc_partial.item())\n",
    "\n",
    "        # 3. Calculate loss\n",
    "        loss = loss_fn(onehot_out, label)\n",
    "        iter_loss.append(loss.item())\n",
    "\n",
    "        # 4. Backward propagation if not in `torch.no_grad()`\n",
    "        if onehot_out.requires_grad:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "\n",
    "        # 5. Save current iteration data for future use\n",
    "        last_out = out.cpu().detach()\n",
    "        last_label = _label\n",
    "\n",
    "    # Up epoch count if backward propagation is done\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    return np.average(iter_loss), np.average(iter_acc), last_out, last_label\n",
    "\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # For now, let's repeat training fixed times, e.g. 25 times.\n",
    "    # We will learn how to determine training stop or continue later.\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "# Logging\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "  \n",
    "  \n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Push time, training loss, training accuracy, and epoch count into lists\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "  \n",
    "  \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Push validation loss and validation accuracy into each list\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "    \n",
    "def last(log_list):\n",
    "    # Get the last member of list. If empty, return -1.\n",
    "    if len(log_list) > 0: return log_list[len(log_list) - 1]\n",
    "    else: return -1\n",
    "\n",
    "\n",
    "def print_log():\n",
    "    # Generate log string and put it into log stack\n",
    "    log_str = f'Iter: {last(iter_log):>4d} >> T_loss {last(tloss_log):<8.5f}   ' \\\n",
    "          + f'T_acc {last(tacc_log):<6.5f}   V_loss {last(vloss_log):<8.5f}   ' \\\n",
    "          + f'V_acc {last(vacc_log):<6.5f}   🕒 {last(time_log):5.3f}s'\n",
    "    log_stack.append(log_str)\n",
    "  \n",
    "  # Draw figure if want\n",
    "    if logging_dispfig:\n",
    "        hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "        hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "        # Draw loss lines\n",
    "        loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='#FF9999', marker='o')\n",
    "        loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='#99B0FF', marker='s')\n",
    "        loss_axis.set_xlabel('epoch')\n",
    "        loss_axis.set_ylabel('loss')\n",
    "\n",
    "        # Draw accuracy lines\n",
    "        acc_axis = loss_axis.twinx()\n",
    "        acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='#FF0000', marker='+')\n",
    "        acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='#003AFF', marker='x')\n",
    "        acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "        # Append annotations\n",
    "        hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "        loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "        loss_axis.grid()\n",
    "        plt.title(f'Learning history until epoch {last(iter_log)}')\n",
    "        plt.draw()\n",
    "    \n",
    "  # Print log\n",
    "    clear_output(wait=True)\n",
    "    if logging_dispfig: plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:50.198335Z",
     "iopub.status.busy": "2021-09-29T08:08:50.198013Z",
     "iopub.status.idle": "2021-09-29T08:08:50.209989Z",
     "shell.execute_reply": "2021-09-29T08:08:50.209324Z",
     "shell.execute_reply.started": "2021-09-29T08:08:50.1983Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mymodel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Mymodel, self).__init__()\n",
    "        \n",
    "        self.hidden_layer1 = 1024\n",
    "        self.hidden_layer2 = 600\n",
    "        self.hidden_layer3 = 200\n",
    "        self.dropout_rate = 0.5\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features, self.hidden_layer1),\n",
    "            nn.BatchNorm1d(self.hidden_layer1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_rate)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer1, self.hidden_layer2),\n",
    "            nn.BatchNorm1d(self.hidden_layer2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_rate)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer2, self.hidden_layer3),\n",
    "            nn.BatchNorm1d(self.hidden_layer3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_rate)\n",
    "        )\n",
    "        self.out_layer = nn.Linear(self.hidden_layer3, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        hidden1 = self.layer1(x)\n",
    "        hidden2 = self.layer2(hidden1)\n",
    "        hidden3 = self.layer3(hidden2)\n",
    "        \n",
    "        onehot_out = self.out_layer(hidden3)\n",
    "        \n",
    "        return onehot_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:50.211968Z",
     "iopub.status.busy": "2021-09-29T08:08:50.211646Z",
     "iopub.status.idle": "2021-09-29T08:08:50.219279Z",
     "shell.execute_reply": "2021-09-29T08:08:50.218497Z",
     "shell.execute_reply.started": "2021-09-29T08:08:50.211931Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "maximum_epoch = 50\n",
    "\n",
    "def init_model(_net):\n",
    "    global net, loss_fn, optim\n",
    "    net = _net.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T08:08:50.534473Z",
     "iopub.status.busy": "2021-09-29T08:08:50.534268Z",
     "iopub.status.idle": "2021-09-29T08:17:40.18338Z",
     "shell.execute_reply": "2021-09-29T08:17:40.182717Z",
     "shell.execute_reply.started": "2021-09-29T08:08:50.53445Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Initialization\n",
    "init_model(Mymodel(len(train_0_x.view([-1])), 10))\n",
    "init_epoch()\n",
    "init_log()\n",
    "\n",
    "# Training Iteration\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    net.train()\n",
    "    tloss, tacc, _, _ = epoch(train_loader)\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        vloss, vacc, _, _ = epoch(valid_loader)\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "    \n",
    "print('\\n Training completed!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-29T04:33:02.300113Z",
     "iopub.status.busy": "2021-09-29T04:33:02.299836Z",
     "iopub.status.idle": "2021-09-29T04:33:04.076281Z",
     "shell.execute_reply": "2021-09-29T04:33:04.075592Z",
     "shell.execute_reply.started": "2021-09-29T04:33:02.300084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save prediction vector to CSV file\n",
    "\n",
    "# Before run this code, here put your save path (only for local server not kaggle kernel)\n",
    "save_root = './submission22.csv'   # <--- only edit this path\n",
    "\n",
    "# After run this code, you must check that the shape of 'out' variable is 3745.\n",
    "# out.shape == torch.Size([3745])\n",
    "\n",
    "\n",
    "# ============================== Do not edit under this line ============================ \n",
    "for _data in test_loader:\n",
    "    data = _data.view([len(_data), -1]).to(device)\n",
    "\n",
    "    # 1. Feed-forward\n",
    "    onehot_out = net(data)\n",
    "    _, out = torch.max(onehot_out, 1)\n",
    "    \n",
    "assert out.shape == torch.Size([3745]), 'Shape of out must torch.Size([3745])'\n",
    "\n",
    "import csv\n",
    "\n",
    "# 덮어쓰기 방지를 위해 이미 파일이 존재하면 삭제\n",
    "if os.path.isfile(save_root):\n",
    "    os.remove(save_root)\n",
    "\n",
    "# 첫 행에 'id' 'lable' 그 다음 행부터 idx와 label 넣어서 csv 저장\n",
    "for idx, pred in enumerate(list(out.cpu())):\n",
    "    with open(save_root, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if idx == 0:\n",
    "            writer.writerow(['Id', 'Category'])\n",
    "        pred = np.concatenate(([idx], [pred]))\n",
    "        writer.writerow(pred)\n",
    "# ============================== Do not edit under this line ============================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저는 캐글안의 환경에서 진행한 후 코드를 저장하여 이 쥬피터 파일에는 결과가 보이지 않습니다.\n",
    "mymodel에서 hidden_layer를 3개로 하고 노드 수와 dropout_rate, learng_rate와 epoch를 직접 설정하여 모델을 돌린 후 캐글에 csv를 올린 결과 0.93410이 나왔습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
