{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim # version 4.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: prepare the corpus for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. 주어진 data로 gensim을 활용하여 word2vec 모델 학습\n",
    "\n",
    "# 학습을 위한 데이터 로딩 -- Data 준비\n",
    "class TextIterator(object):\n",
    "\tdef __init__(self, fname):\n",
    "\t\tself.fname = fname\n",
    "\n",
    "\tdef __iter__(self):\n",
    "\t\tfor line in open(self.fname):\n",
    "\t\t\tyield line.split()\n",
    "\n",
    "filename = 'newskor.txt'\n",
    "sentences = TextIterator(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2, 3: Training & Load Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "train = False # train flag (True: train model / False: load trained model)\n",
    "SIZE = 300 # vector size\n",
    "WINDOW = 5 # context window\n",
    "SG = 1 # 1 for skip-gram / otherwise cbow\n",
    "MIN_COUNT = 10 # ignores all words appearing lower than min_count\n",
    "WORKERS = 20 # cpu cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    model = gensim.models.Word2Vec(\n",
    "        vector_size=SIZE, window=WINDOW, sg=SG, \n",
    "        min_count=MIN_COUNT, workers=WORKERS\n",
    "    )\n",
    "    model.build_vocab(sentences) # prepare model vocab\n",
    "    model.train(sentences, total_examples=model.corpus_count, epochs=5)\n",
    "    model.save('newskor.model')\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load('newskor.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 하\n",
      "1: 이\n",
      "2: .\n",
      "3: 는\n",
      "4: 을\n",
      "5: ㄴ\n",
      "6: 다\n",
      "7: 의\n",
      "8: 에\n",
      "9: 를\n",
      "10: 은\n",
      "11: 어\n",
      "12: 있\n",
      "13: 고\n",
      "14: 으로\n",
      "15: 가\n",
      "16: 였\n",
      "17: ㄹ\n",
      "18: 되\n",
      "19: ,\n",
      "20: 에서\n",
      "21: 었\n",
      "22: )\n",
      "23: (\n",
      "24: 로\n",
      "25: 것\n",
      "26: 도\n",
      "27: 등\n",
      "28: 과\n",
      "29: 들\n",
      "30: 지\n"
     ]
    }
   ],
   "source": [
    "vocab = model.wv.index_to_key # See vocabs\n",
    "for i, v in enumerate(vocab):\n",
    "    print(\"{}: {}\".format(i, v))\n",
    "    if i==30: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2715847  -0.4110245   0.05292874  0.25203902 -0.43354133 -0.31395456\n",
      " -0.38652474  0.17409396  0.09732261  0.0857102   0.33092657  0.15264848\n",
      " -0.06908963  0.15235962  0.00971851 -0.07327552 -0.09597956  0.03339197\n",
      " -0.14834644 -0.2842372  -0.03190251 -0.4458092  -0.58018994 -0.43267536\n",
      " -0.10747258 -0.5685088   0.03274008 -0.12354413  0.41608647 -0.24299626\n",
      "  0.22650497 -0.07594266  0.02808464 -0.43623492 -0.48877466  0.16534336\n",
      " -0.47772175 -0.3533794   0.0497962   0.38129923  0.24344234 -0.22787471\n",
      "  0.3143169   0.19553974  0.02521827  0.02969735 -0.03262899  0.11954125\n",
      " -0.188389    0.16422062  0.51755726  0.05637418  0.08843178  0.31328052\n",
      "  0.429697    0.4868151   0.14308344 -0.13715728 -0.274024    0.07898688\n",
      "  0.15081364  0.05356184 -0.02355863  0.02049953 -0.26301914  0.31544527\n",
      "  0.09945583 -0.39227945 -0.32577708 -0.05783262 -0.04052503  0.11624837\n",
      " -0.05318096  0.04025342  0.5278434   0.13758366  0.18236583  0.19009952\n",
      "  0.18445383 -0.13050452  0.06278759  0.1667132   0.25121257  0.10697582\n",
      " -0.36646426  0.2166943  -0.21697465  0.126149   -0.04249876  0.3811559\n",
      " -0.08048418 -0.16208103 -0.52473253  0.06603312  0.3112922   0.10002469\n",
      " -0.00835883 -0.08609056 -0.26642993  0.17603877  0.23881133  0.21889977\n",
      " -0.07010709  0.10443681 -0.020529    0.1367376  -0.02749301  0.30645847\n",
      "  0.04718182 -0.02133274  0.09015823 -0.16736917  0.19696037 -0.48695913\n",
      " -0.06137135  0.13456723  0.12049851 -0.02073156  0.18436056 -0.01610034\n",
      "  0.13202947 -0.31973192  0.00329836 -0.25522962  0.06467757 -0.10821778\n",
      "  0.1290495  -0.3616548  -0.14760043 -0.48986796  0.24054827  0.07534213\n",
      " -0.11427659 -0.16939345  0.35918078  0.00578237  0.12164452  0.22394133\n",
      " -0.03110395 -0.16719061 -0.23833328 -0.2987228   0.02142767  0.03045704\n",
      "  0.35688516  0.2392319  -0.3068551   0.11517046 -0.01609351  0.1451854\n",
      " -0.43623373 -0.0757172  -0.18638138 -0.568894    0.19258268  0.13840364\n",
      "  0.16682152  0.31007084 -0.27021015  0.13757479  0.08849894  0.39332625\n",
      " -0.4060767   0.07049    -0.14580545  0.13959275  0.0299557  -0.45015493\n",
      "  0.46896356  0.2481153  -0.01968621 -0.5237726   0.21636389 -0.22441903\n",
      "  0.19228114  0.0662186   0.278187   -0.16820529  0.16197725  0.15610227\n",
      "  0.47731513  0.22464333 -0.23402697 -0.31412238  0.43234268 -0.31706405\n",
      "  0.17814232  0.02227537 -0.06441312  0.13156207  0.21949142 -0.55027837\n",
      " -0.04927841 -0.07841558 -0.05675903 -0.24837191  0.16774578  0.25400755\n",
      " -0.22898711 -0.02754872  0.18467253 -0.09547769  0.534419   -0.33401275\n",
      " -0.24436375  0.1282025  -0.14315104 -0.22616918  0.25568965 -0.02341857\n",
      " -0.42258993 -0.53891754 -0.02114632 -0.22059363  0.32186678 -0.59497815\n",
      "  0.5845225  -0.28758138  0.02796693 -0.2776742   0.33486372 -0.02974784\n",
      "  0.16216609 -0.23787312  0.29454303  0.07868195 -0.2791744  -0.02858193\n",
      " -0.12431148  0.28863356 -0.3820798  -0.5437826  -0.23264593 -0.09063575\n",
      " -0.04565164  0.02376054 -0.017531    0.28467196 -0.12329468 -0.13438387\n",
      "  0.22979504 -0.11997876  0.10326053  0.02761187  0.4875899  -0.1009043\n",
      " -0.2617744  -0.0523519  -0.18210068  0.44909564 -0.10619032 -0.13803758\n",
      "  0.38542038 -0.08817474  0.19641751 -0.3305027   0.08943997  0.2505103\n",
      "  0.19210595 -0.28199014  0.06921145  0.376775   -0.04825879 -0.08557809\n",
      "  0.07481886  0.17342769  0.38495517  0.130451   -0.6466138   0.43602064\n",
      " -0.15250945  0.11078694 -0.05514616 -0.429087   -0.05751743 -0.05550375\n",
      "  0.8242801   0.5127624  -0.43773758  0.21760453 -0.0797193   0.23905393\n",
      "  0.19504209 -0.12353972 -0.10264692 -0.45727494 -0.1590029   0.14922844\n",
      "  0.46473554  0.23380357  0.19746223  0.4319475   0.4740918   0.17338103\n",
      "  0.0448086   0.11738247  0.13482869 -0.05601439  0.60505074 -0.22082038]\n",
      "size of vector:  300\n"
     ]
    }
   ],
   "source": [
    "## check word embed result\n",
    "word = '버스'\n",
    "print(model.wv[word])\n",
    "print('size of vector: ', len(model.wv[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4: Get word similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caculate the similarity between word 1 and word2\n",
      "the similarity between 한국 and 북한 :  0.3075229\n"
     ]
    }
   ],
   "source": [
    "#word1 = '한국'\n",
    "#word2 = '북한'\n",
    "print (\"Caculate the similarity between word 1 and word2\")\n",
    "word1 = input(\"word1: \")\n",
    "word2 = input(\"word2: \")\n",
    "\n",
    "# check the words are in the vocabulary\n",
    "no_problem = True\n",
    "vocab = model.wv.index_to_key\n",
    "\n",
    "if word1 not in vocab:\n",
    "\tprint ('the word ' + word1 + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if word2 not in vocab:\n",
    "\tprint ('the word ' + word2 + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if no_problem:\n",
    "\tsimilarity = model.wv.similarity(word1, word2)\n",
    "\tprint ('the similarity between ' + word1 + ' and ' + word2 + ' : ', similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5: Find mismatch word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find mismatched word in the words\n",
      "text(words): 소프트웨어 네트워크 프로그램 가방\n",
      "the mismatch word between 소프트웨어 네트워크 프로그램 가방 is 가방\n"
     ]
    }
   ],
   "source": [
    "#words = '소프트웨어 네트워크 프로그램 가방'\n",
    "print(\"Find mismatched word in the words\")\n",
    "text = input(\"text(words): \")\n",
    "words = text.split()\n",
    "\n",
    "# check the words are in the vocabulary\n",
    "no_problem = True\n",
    "vocab = model.wv.index_to_key\n",
    "\n",
    "for word in words:\n",
    "\tif word not in vocab:\n",
    "\t\tprint('the word ' + word + ' is not in the vocabulary')\n",
    "\t\tno_problem = False\n",
    "\t\tbreak;\n",
    "\n",
    "if no_problem:\n",
    "\tmismatched = model.wv.doesnt_match(words)\n",
    "\tprint ('the mismatch word between ' + text +' is', mismatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Find the top-N most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the most similar words\n",
      "word: 인간\n",
      "[('동물', 0.617953896522522), ('배아', 0.6104809641838074), ('생쥐', 0.5970973968505859), ('존엄성', 0.5852876901626587), ('본성', 0.5809779167175293), ('인류', 0.5760883092880249), ('생명체', 0.5717364549636841), ('유기체', 0.5703120827674866), ('핵이식', 0.5635316371917725), ('욕망', 0.561828076839447)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print the most similar words\")\n",
    "word = input(\"word: \")\n",
    "\n",
    "no_problem = True\n",
    "vocab = model.wv.index_to_key\n",
    "\n",
    "if word not in vocab:\n",
    "\tprint ('the word ' + word + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if no_problem:\n",
    "    print(model.wv.most_similar(positive=[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Vector calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find the most similar word with the result of [ a - b + c ]\n",
      "a: 독도\n",
      "b: 한국\n",
      "c: 일본\n",
      "most similar word of 독도 - 한국 + 일본 is 다케시마 영유권 울릉도\n"
     ]
    }
   ],
   "source": [
    "#word_a = '한국'\n",
    "#word_b = '아시아'\n",
    "#word_c = '유럽'\n",
    "print('Find the most similar word with the result of [ a - b + c ]')\n",
    "word_a = input(\"a: \")\n",
    "word_b = input(\"b: \")\n",
    "word_c = input(\"c: \")\n",
    "\n",
    "# check the words are in the vocabulary\n",
    "no_problem = True\n",
    "vocab = model.wv.index_to_key\n",
    "\n",
    "if word_a not in vocab:\n",
    "\tprint ('the word ' + word_a + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if word_b not in vocab:\n",
    "\tprint ('the word ' + word_b + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if word_c not in vocab:\n",
    "\tprint ('the word ' + word_c + ' is not in the vocabulary')\n",
    "\tno_problem = False\n",
    "\n",
    "if no_problem:\n",
    "\tmostsimilar = model.wv.most_similar(positive=[word_a, word_c], negative=[word_b], topn=5)\n",
    "\tprint ('most similar word of ' + word_a + ' - ' + word_b + ' + ' + word_c + ' is', mostsimilar[0][0], mostsimilar[1][0], mostsimilar[2][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8cd164ad5a79a462ee0eb2d2e7f5baf60f22866e96314cac02a3dda22ea6de36"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}